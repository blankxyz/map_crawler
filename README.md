# 使用说明

本文档将指导您如何安装、运行和使用基于 Next.js、TypeScript、Playwright 和 Socket.IO 构建的爬虫控制面板应用程序。

## 目录

1. [项目简介](#项目简介)
2. [系统要求](#系统要求)
3. [安装步骤](#安装步骤)
4. [编译爬虫脚本](#编译爬虫脚本)
5. [运行应用程序](#运行应用程序)
6. [使用爬虫控制面板](#使用爬虫控制面板)
7. [查看爬虫日志](#查看爬虫日志)
8. [查看生成的 CSV 文件](#查看生成的-csv-文件)
9. [常见问题与解决方案](#常见问题与解决方案)
10. [注意事项](#注意事项)
11. [结论](#结论)

---

## 项目简介

该应用程序是一个基于 **Next.js** 和 **TypeScript** 构建的爬虫控制面板，使用 **Playwright** 进行网页爬取，并通过 **Socket.IO** 实现实时日志显示。用户可以通过网页界面输入要爬取的 URL，启动或中止爬虫程序，并实时查看爬虫日志和生成的 CSV 文件。

---

## 系统要求

- **操作系统**：Windows、macOS 或 Linux
- **Node.js**：版本 >= 14.x.x
- **npm**：版本 >= 6.x.x
- **浏览器**：现代浏览器（Chrome、Firefox、Edge 等）

---

## 安装步骤

### 1. 克隆项目代码

使用 `git` 将项目代码克隆到本地：

```bash
git clone https://github.com/your-username/crawler-dashboard.git
```

### 2. 进入项目目录

```bash
cd crawler-dashboard
```

### 3. 安装依赖

```bash
npm install
```

此命令将安装项目所需的所有依赖包，包括：

- Next.js
- React 和 React DOM
- TypeScript 及其类型定义
- Playwright 及其类型定义
- Socket.IO 和 Socket.IO Client

### 4. 安装 Playwright 浏览器

```bash
npx playwright install
```

此命令将安装 Playwright 所需的浏览器，以便进行网页爬取。

---

## 编译爬虫脚本

在运行应用程序之前，需要先编译爬虫脚本 `crawler.ts`。

```bash
npm run build:crawler
```

此命令将使用 TypeScript 编译爬虫脚本，生成 `dist/crawler/crawler.js` 文件。

---

## 运行应用程序

### 1. 启动开发服务器

```bash
npm run dev
```

此命令将启动自定义服务器，该服务器使用 Express 和 Socket.IO，并集成了 Next.js 应用程序。

### 2. 访问应用程序

在浏览器中打开：

```
http://localhost:3001
```

**注意**：如果您在 `server.js` 中更改了端口号，请使用相应的端口访问。

---

## 使用爬虫控制面板

### 1. 输入 URL

在页面顶部的输入框中，输入您要爬取的目标网站的 URL，例如：

```
https://example.com
```

### 2. 启动爬虫

点击 **“启动爬虫”** 按钮，开始爬取指定的网站。

- **注意**：在爬虫运行期间，输入框和 **“启动爬虫”** 按钮将被禁用，防止重复启动。

### 3. 中止爬虫

如果您希望停止爬虫的运行，点击 **“中止爬虫”** 按钮。

- **注意**：在爬虫未运行时，**“中止爬虫”** 按钮将被禁用。

---

## 查看爬虫日志

在 **“爬虫日志”** 区域，您可以实时查看爬虫的运行日志，包括：

- 访问的 URL
- 爬取的深度和目录深度
- 运行时间和页面数量
- 错误信息

日志区域支持滚动，您可以查看完整的日志信息。

---

## 查看生成的 CSV 文件

### 1. 刷新文件列表

在 **“生成的 CSV 文件”** 区域，点击 **“刷新文件列表”** 按钮，获取最新的 CSV 文件列表。

### 2. 下载或查看文件

文件列表中将显示所有生成的 CSV 文件。点击文件名即可下载或在浏览器中查看文件内容。

- **文件说明**：
  - `directories_depth_{depth}.csv`：存储不同目录深度的目录信息。
  - `failed_links.csv`：记录访问失败的链接及其原因。
  - `abandoned_links.csv`：记录被放弃的链接。

---

## 常见问题与解决方案

### 问题 1：端口已被占用

**错误信息**：

```
Error: listen EADDRINUSE: address already in use :::3001
```

**解决方案**：

- 确认是否有其他应用程序占用了端口 `3001`。
- 结束占用端口的进程，或在 `server.js` 中修改端口号。

### 问题 2：无法获取文件列表

**错误原因**：

- `public/data` 目录不存在或无权限访问。
- 爬虫尚未生成任何 CSV 文件。

**解决方案**：

- 确保 `public/data` 目录存在，如无则手动创建。
- 确保应用程序有权限访问该目录。
- 运行爬虫以生成 CSV 文件。

### 问题 3：爬虫日志未显示

**可能原因**：

- Socket.IO 连接未建立。
- 服务器端未正确配置 Socket.IO。

**解决方案**：

- 检查浏览器控制台是否有连接错误。
- 确保服务器端的 `crawlerManager` 正确传递了 `io` 对象。
- 检查 `server.js` 中的 Socket.IO 配置。

---

## 注意事项

- **合法合规**：在爬取网站前，请确保遵守目标网站的 `robots.txt` 协议和相关法律法规，尊重目标网站的隐私和使用条款。
- **资源消耗**：爬虫运行可能会消耗较多的系统资源，建议在性能较好的机器上运行，避免影响其他应用程序的运行。
- **安全性**：对用户输入的 URL 进行验证，防止命令注入和其他安全问题。
- **数据备份**：定期备份生成的 CSV 文件，防止数据丢失。

---

## 结论

通过本使用说明，您应当能够成功安装、运行并使用爬虫控制面板应用程序。该应用程序提供了直观的界面，方便您启动和管理爬虫任务，并实时查看爬虫日志和生成的文件。

如果您在使用过程中遇到任何问题，欢迎提出，我们将尽力协助您解决。

**感谢您的使用！**